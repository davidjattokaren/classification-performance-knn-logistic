{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a92daa1",
   "metadata": {},
   "source": [
    "# An Outline for the Tasks Ahead..\n",
    "\n",
    "Before we begin solving any business problem that requires modelling of data, it is paramount that we complete the below checklist items (as part of a standard process regardless of the problem statement or/and domain):\n",
    "\n",
    "- [ ] Business Requirements Gathering / Problem Identification (Background Information)\n",
    "- [ ] Pre-requisites setup (Importing packages, etc.)\n",
    "- [ ] Data source identification and access\n",
    "- [ ] Exploratory Data Analysis\n",
    "- [ ] Data Preparation\n",
    "- [ ] Model Building & Evaluation\n",
    "- [ ] Model Deployment\n",
    "\n",
    "While the activities above are not exhaustive, they cover the core requirements of any data modelling exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6afe30",
   "metadata": {},
   "source": [
    "# Table of Contents: <a class=\"anchor\" id=\"table-of-content\"></a>\n",
    "* [1. Problem Background and Motivation](#problem-background)\n",
    "* [2. Libraries and Custom Functions](#import-packages)\n",
    "* [3. Data Exploration/Prep](#data-prep)\n",
    "* [4. Machine Learning Model](#ml-model)\n",
    "* [5. Deployment of Model](#model-deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68270d0",
   "metadata": {},
   "source": [
    "# 1. Problem Background and Motivation <a class=\"anchor\" id=\"problem-background\"></a>\n",
    "\n",
    "<img src='' width=\"700\" />\n",
    "\n",
    "### Problem Description\n",
    ">- A large regional bank would like to automate their loan approval process to reduce costs, time for approval, and ambiguity (of the process). As a part of this goal, they want to build a machine learning solution that can use the data provided by customers to make a decision on whether the loan should be approved for an applicant or not. However, the data provided contains some information of applicants that cannot (legally) be used to make loan approval decisions and hence these need to be mandatorily excluded.\n",
    "\n",
    "### Key Stakeholders\n",
    ">- Loan Officers - This solution would be primarily geared towards loan officers, who can use the solution to (almost) instantly get a decision on whether an applicant's loan should be approved or not.\n",
    "\n",
    ">- Bank Managers - Bank managers can use the solution as well to understand what kind of applicants tend to be approved (or not). In the hypothetical scenario where this solution replaces Loan Officers, the bank manager would be the primary stakeholder for this solution.\n",
    "\n",
    "* [Go to Top](#table-of-content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afada7a",
   "metadata": {},
   "source": [
    "# 2. Libraries & Custom Functions <a class=\"anchor\" id=\"import-packages\"></a>\n",
    "* [Go to Top](#table-of-content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ece0c",
   "metadata": {},
   "source": [
    "##### Libraries Import:\n",
    ">- Pandas for data processing and transformation. Numpy for numerical functions\n",
    ">- Seaborn, Matplotlib and Ploty for visual representations of data / function outputs\n",
    ">- (Sklearn) Train_Test_Split to split our data into randomized train and test dataframes.\n",
    ">- (Sklearn) LogisticRegression to implement a logistic regression model\n",
    ">- (Sklearn) NearestNeighbors, KNeighborsClassifier to implement a KNN classification model\n",
    ">- (Sklearn) Metrics to measure classification performance\n",
    ">- Pickle to serialize our model object so that it can be used in Streamlit\n",
    ">- Streamlit to deploy a GUI which can be used to interact with the model\n",
    "\n",
    "##### Custom Functions:\n",
    ">- Class_Perf_Measures - a function that takes the model object, X_test (which contains the test data predictor variables), Y_test (which contains the test data target variable) to calculate and display performance measures such as recall, precision, and confusion matrix metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590f96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import numpy as np\n",
    "\n",
    "# Graphics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Deployment\n",
    "import pickle\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "# Custom function below is used to display performance measures\n",
    "# Required inputs are the model name and the two test data objects (X,y)\n",
    "def class_perf_measures(model,X_test,y_test):\n",
    "    # Create empty lists to store metric values created within loop\n",
    "    TP = []\n",
    "    TN = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    F1 = []\n",
    "    Accuracy = []\n",
    "    \n",
    "    # Create list of probability threshold values to loop over\n",
    "    threshold = np.arange(0,1.1,0.1).tolist()\n",
    "\n",
    "    # Start loop\n",
    "    for i in threshold:\n",
    "\n",
    "        # Create class assignments given threshold value\n",
    "        y_test_pred_class = (model.predict_proba(X_test)[:,1] >= i).astype(int)\n",
    "\n",
    "        # Append lists with metric values\n",
    "        TP.append(metrics.confusion_matrix(y_test, y_test_pred_class)[1,1])\n",
    "        TN.append(metrics.confusion_matrix(y_test, y_test_pred_class)[0,0])\n",
    "        FP.append(metrics.confusion_matrix(y_test, y_test_pred_class)[0,1])\n",
    "        FN.append(metrics.confusion_matrix(y_test, y_test_pred_class)[1,0])\n",
    "        recall.append(metrics.recall_score(y_test, y_test_pred_class).round(3))\n",
    "        precision.append(metrics.precision_score(y_test, y_test_pred_class).round(3))\n",
    "        F1.append(metrics.f1_score(y_test, y_test_pred_class).round(2))\n",
    "        Accuracy.append(metrics.accuracy_score(y_test, y_test_pred_class).round(2))\n",
    "\n",
    "    # Create dataframe\n",
    "    result = pd.DataFrame({\"threshold\":threshold,\n",
    "                           \"TP\":TP,\n",
    "                           \"TN\":TN,\n",
    "                           \"FP\":FP,\n",
    "                           \"FN\":FN,\n",
    "                           \"Precision\":precision,\n",
    "                           \"Recall\":recall,\n",
    "                           \"F1\":F1,\n",
    "                           \"Accuracy\": Accuracy\n",
    "                          })\n",
    "\n",
    "    # Let's look at our dataframe\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fe86e",
   "metadata": {},
   "source": [
    "# 3. Data Exploration/Prep <a class=\"anchor\" id=\"data-prep\"></a>\n",
    "\n",
    "- [ ] [Initial Evaluation](#initial-evaluation)\n",
    "- [ ] [Initial Cleanup - dupes, missing values](#missing-values)\n",
    "- [ ] [Outlier Detection & Treatment](#outliers)\n",
    "- [ ] [Feature Selection](#feature-selection)\n",
    "- [ ] [Data Partitioning](#data-split)\n",
    "- [ ] [Data Normalization](#normalization)\n",
    "\n",
    "[Go to Top of Notebook](#table-of-content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a016ec2",
   "metadata": {},
   "source": [
    "> **Initial Evaluation** <a class=\"anchor\" id=\"initial-evaluation\"></a>\n",
    "\n",
    "We read in the dataset (provided in CSV format) and look at the last 5 rows just to get a high level understanding of the kind of variables we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04394553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>debt</th>\n",
       "      <th>married</th>\n",
       "      <th>bank_customer</th>\n",
       "      <th>emp_industrial</th>\n",
       "      <th>emp_materials</th>\n",
       "      <th>emp_consumer_services</th>\n",
       "      <th>emp_healthcare</th>\n",
       "      <th>emp_financials</th>\n",
       "      <th>emp_utilities</th>\n",
       "      <th>emp_education</th>\n",
       "      <th>ethnicity_white</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_latino</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_other</th>\n",
       "      <th>years_employed</th>\n",
       "      <th>prior_default</th>\n",
       "      <th>employed</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>drivers_license</th>\n",
       "      <th>citizen_bybirth</th>\n",
       "      <th>citizen_other</th>\n",
       "      <th>citizen_temporary</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     approved  gender   age  debt  married  bank_customer  emp_industrial  \\\n",
       "685         0       1 21.08 10.09        0              0               0   \n",
       "686         0       0 22.67  0.75        1              1               1   \n",
       "687         0       0 25.25 13.50        0              0               0   \n",
       "688         0       1 17.92  0.20        1              1               0   \n",
       "689         0       1 35.00  3.38        1              1               1   \n",
       "\n",
       "     emp_materials  emp_consumer_services  emp_healthcare  emp_financials  \\\n",
       "685              0                      0               0               0   \n",
       "686              0                      0               0               0   \n",
       "687              0                      0               1               0   \n",
       "688              0                      1               0               0   \n",
       "689              0                      0               0               0   \n",
       "\n",
       "     emp_utilities  emp_education  ethnicity_white  ethnicity_black  \\\n",
       "685              0              1                0                1   \n",
       "686              0              0                1                0   \n",
       "687              0              0                0                0   \n",
       "688              0              0                1                0   \n",
       "689              0              0                0                1   \n",
       "\n",
       "     ethnicity_latino  ethnicity_asian  ethnicity_other  years_employed  \\\n",
       "685                 0                0                0            1.25   \n",
       "686                 0                0                0            2.00   \n",
       "687                 1                0                0            2.00   \n",
       "688                 0                0                0            0.04   \n",
       "689                 0                0                0            8.29   \n",
       "\n",
       "     prior_default  employed  credit_score  drivers_license  citizen_bybirth  \\\n",
       "685              0         0             0                0                1   \n",
       "686              0         1             2                1                1   \n",
       "687              0         1             1                1                1   \n",
       "688              0         0             0                0                1   \n",
       "689              0         0             0                1                1   \n",
       "\n",
       "     citizen_other  citizen_temporary  Income  \n",
       "685              0                  0       0  \n",
       "686              0                  0     394  \n",
       "687              0                  0       1  \n",
       "688              0                  0     750  \n",
       "689              0                  0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We read the dataset that was provided to us\n",
    "df = pd.read_csv('loan_approval.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1c8ef",
   "metadata": {},
   "source": [
    "**Approved** is our target variable, while the rest are potential predictor variables. 1 indicates approved, 0 indicates not approved.\n",
    "\n",
    "**Gender** indicates whether male or female. However we will not use this variable as it is unethical to make lending decisions based on gender.\n",
    "\n",
    "**age** tells us the age. However we will not use this variable as it is unethical to make lending decisions based on age.\n",
    "\n",
    "**debt** tell us the amount of debt the applicant currently has (NUMERIC)\n",
    "\n",
    "**married** tells us if married (1) or not (0)\n",
    "\n",
    "**bank_customer** tells us if the person is a customer of the bank (1) or not (0)\n",
    "\n",
    "**emp_X** tells us the industry in which the applicant works (industrial, materials, consumer services, healthcare, financials, utilities, education \n",
    "\n",
    "**ethnicity_X** tells us the ethnicity of the applicant. However we will not use this variable as it is unethical to make lending decisions based on ethnicity.\n",
    "\n",
    "**years_employed** tells us the number of years the applicant was employed for (NUMERIC)\n",
    "\n",
    "**prior_default** tells us if the applicant has previously default on a loan (1) or not (0)\n",
    "\n",
    "**employed** tells us if the applicant is employed (1) or not (0). However, I will not use this as it is already covered / explained in more detail by **emp_X**\n",
    "\n",
    "**credit_score** tells us the level of the applicant's credit score. While these are technically categorical, we can leave them as numeric since there is a natural order of values.\n",
    "\n",
    "**drivers_license** tells us if the applicant has a drivers license (1) or not (0)\n",
    "\n",
    "**citizen_X** tells us if the applicant is a citizen by birth, other or is a temporary resident. We CAN use this variable as it is a reflection of immigration status (which can be used) rather than country of origin (which cannot be used).\n",
    "\n",
    "**Income** tells us the income of the applicant (NUMERIC).\n",
    "\n",
    "As the data is already clean with no missing values, duplicates, and serious outliers, we can proceed directly to the train / test split. It also looks like all variables (except where indicated) are useful for the purposes of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a9b4c",
   "metadata": {},
   "source": [
    "> **Initial Cleanup - dupes, missing values** <a class=\"anchor\" id=\"missing-values\"></a>\n",
    "\n",
    "In this step, we remove duplicates (if any) and treat missing values.\n",
    "\n",
    "This step is not needed as the data is already confirmed to be free of duplicates and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82145d5",
   "metadata": {},
   "source": [
    "> **Outlier Detection & Treatment** <a class=\"anchor\" id=\"outliers\"></a>\n",
    "\n",
    "In this step, we look at summary statistics and graphical distributions to understand if outliers exist.\n",
    "\n",
    "This step is not needed as the data is already confirmed to be free of any serious outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9314f61",
   "metadata": {},
   "source": [
    "> **Feature Selection** <a class=\"anchor\" id=\"feature-selection\"></a>\n",
    "\n",
    "We select the features that are to be used in our model.\n",
    "In the case of this problem statement, we will use ALL of the provided variables.\n",
    "<br>\n",
    "\n",
    ">**Completed:**<br>\n",
    "> 1. One hot encoding of categorical variables<br>\n",
    "Note - we are not dropping any of the dummy variables as all dummies are needed for classifcation algorithms\n",
    "\n",
    ">**To Do:**<br>\n",
    "> 1. Drop the variables that are considered unethical to use for loan approvals + employed (which is already explained by other variables)\n",
    "> 2. Split the data into train and test<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38143b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['gender', 'age', 'ethnicity_white', 'ethnicity_black', 'ethnicity_latino',\n",
    "       'ethnicity_asian', 'ethnicity_other', 'employed']\n",
    "\n",
    "df = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f2a66",
   "metadata": {},
   "source": [
    "> **Data Partitioning** <a class=\"anchor\" id=\"data-split\"></a>\n",
    "\n",
    "In this step we partition the data into \"train\" and \"test\" sets. We use the train_test_split function that splits the data into random train and test subsets.\n",
    "<br>\n",
    "\n",
    "> **To Do:**<br>\n",
    ">1. Put all potential predictor variables into new object called 'X'\n",
    ">2. Put target variable in new object called 'y'\n",
    ">3. Partition data into training set and testing set<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910b9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['approved']\n",
    "\n",
    "X = df.drop(target,axis=1)\n",
    "y = df[target]\n",
    "\n",
    "# Split data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009490e",
   "metadata": {},
   "source": [
    "> **Data Normalization** <a class=\"anchor\" id=\"normalization\"></a>\n",
    "<br><br>\n",
    ">**Note:**<br>\n",
    ">We do this AFTER splitting the data because we only want to use summary stats<br>\n",
    ">from the TRAINING data to normalize BOTH TRAIN and TEST data<br>\n",
    "<br><br>\n",
    ">We first need to split the dataset so that we only normalize the numeric variables. Once normalized, we then recreate the dataset by combining the normalized numeric variables with the categorical (dummy) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1516892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize predictor variables using Z-Scores.\n",
    "# Use means and standard deviations of features as calculated in the TRAINING DATA\n",
    "# New values are centered at 0.  Values reflect the number of standard deviations\n",
    "# each record is above or below the mean.\n",
    "\n",
    "X_train_dummy = X_train[['married', 'bank_customer', 'emp_industrial',\n",
    "       'emp_materials', 'emp_consumer_services', 'emp_healthcare',\n",
    "       'emp_financials', 'emp_utilities', 'emp_education', 'prior_default', 'credit_score', 'drivers_license', 'citizen_bybirth',\n",
    "       'citizen_other', 'citizen_temporary']]\n",
    "X_train = X_train[[\"debt\", \"years_employed\", \"Income\"]]\n",
    "\n",
    "X_test_dummy = X_test[['married', 'bank_customer', 'emp_industrial',\n",
    "       'emp_materials', 'emp_consumer_services', 'emp_healthcare',\n",
    "       'emp_financials', 'emp_utilities', 'emp_education', 'prior_default', 'credit_score', 'drivers_license', 'citizen_bybirth',\n",
    "       'citizen_other', 'citizen_temporary']]\n",
    "X_test = X_test[[\"debt\", \"years_employed\", \"Income\"]]\n",
    "\n",
    "features_means = X_train.mean()\n",
    "features_std = X_train.std()\n",
    "\n",
    "X_train = (X_train - features_means)/features_std\n",
    "X_test = (X_test - features_means)/features_std\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_dummy], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cb609",
   "metadata": {},
   "source": [
    "We have normalized the numeric variable (employee experience). We first separate the dummy variables and numeric, applied the Z scaling technique to employee experience, and then concatenated the dummy and scaled employee experience together to create the final X_train and X_test dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4070cf",
   "metadata": {},
   "source": [
    "# 4. Machine Learning <a class=\"anchor\" id=\"ml-model\"></a>\n",
    "\n",
    "We now begin to create our KNN and Logistic Models. \n",
    "\n",
    "For KNN, we first try various values of k (from 1 to 21, step of 2). We then choose a high level performance measure (in this case, accuracy) for comparison purposes. Then we choose the best value for k based on Accuracy (while ensuring this k value is not too high or too low, to avoid underfitting / overfitting).\n",
    "\n",
    "For the Logistic Model, we simply pass the training data to the LogisticRegression model object.\n",
    "\n",
    "For both models, we first observe the train and test accuracy to ensure that overfitting / underfitting is not present. Once this is complete, we calculate the AUC and choose the winning model as the one with the highest AUC.\n",
    "\n",
    "Post this, we evaluate the performance of our winning model so that we can choose an ideal probability threshold. This step is to be completed in the context of the business problem (what is more expensive / risky for the business? false positives or false negatives?)\n",
    "\n",
    "- [X] [kNN](#first-model)\n",
    "- [X] [Logistic Model](#second-model)\n",
    "- [ ] [Performance Evaluation](#third-model)\n",
    "\n",
    "\n",
    "* [Go to Top](#table-of-content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d7df8",
   "metadata": {},
   "source": [
    "> **kNN** <a class=\"anchor\" id=\"first-model\"></a>\n",
    "<br>\n",
    ">Steps to Complete:<br>\n",
    ">1. Fit numerous kNN models using different values for k. <br>\n",
    ">2. Choose the \"best\" value for \"k\" based on Accuracy\n",
    ">3. Ensure a k value that is not too low (leads to overfitting) and not too high (leads to underfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5988187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy\n",
       "0    1      0.77\n",
       "1    3      0.81\n",
       "2    5      0.83\n",
       "3    7      0.80\n",
       "4    9      0.79\n",
       "5   11      0.78\n",
       "6   13      0.81\n",
       "7   15      0.79\n",
       "8   17      0.79\n",
       "9   19      0.80\n",
       "10  21      0.80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. train a classifier for different values of k\n",
    "results = []\n",
    "for k in [1,3,5,7,9,11,13,15,17,19,21]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train.values.ravel())\n",
    "    \n",
    "    # Get predicted class\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "    \n",
    "    # Put Accuracy Score in results object\n",
    "    results.append({'k':k,\n",
    "                    'accuracy':metrics.accuracy_score(y_test,y_pred_class)\n",
    "                   }\n",
    "                  )\n",
    "# Put results from above into a Pandas Dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3ee11",
   "metadata": {},
   "source": [
    ">**Decision:**<br>\n",
    "Based on the results above, I will set my number of neighbors (k) to 5 as this is the lowest value of k that achieves the highest accuracy value.<br>\n",
    "\n",
    ">**Re-run kNN using the value selected above:**<br>\n",
    "For this final run of kNN, we will produce a table of performance measures across a range of probability threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1f09dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Accuracy: 0.89\n",
      "Testing data Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "# Let's do a quick check to see if we have to worry about problems of overfitting.\n",
    "# Remember!  Small values for \"k\" in kNN tend to lead to overfitting.\n",
    "# Large value for \"k\" in kNN tend to produce underfit models\n",
    "y_train_pred_class = knn.predict(X_train)\n",
    "y_test_pred_class = knn.predict(X_test)\n",
    "\n",
    "print('Training data Accuracy:', metrics.accuracy_score(y_train,y_train_pred_class).round(2))\n",
    "print('Testing data Accuracy:', metrics.accuracy_score(y_test,y_test_pred_class).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc63642",
   "metadata": {},
   "source": [
    "There is no major evidence of overfitting or underfitting as the accuracy values of training and testing data are similar (89% vs. 83%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9d5f2",
   "metadata": {},
   "source": [
    ">**Logistic Model:**<br>\n",
    ">We produce the same table above but this time using a Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5a2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Accuracy: 0.88\n",
      "Testing data Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "# Let's do a quick check to see if we have to worry about problems of overfitting.\n",
    "\n",
    "y_train_pred_class = lr_model.predict(X_train)\n",
    "y_test_pred_class = lr_model.predict(X_test)\n",
    "\n",
    "print('Training data Accuracy:', metrics.accuracy_score(y_train,y_train_pred_class).round(2))\n",
    "print('Testing data Accuracy:', metrics.accuracy_score(y_test,y_test_pred_class).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103cba3",
   "metadata": {},
   "source": [
    "There is no evidence of overfitting or underfitting as the accuracy values of training and testing data are similar (88% vs. 86%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe4d2f",
   "metadata": {},
   "source": [
    ">**Winning Model:**<br>\n",
    "We need to quickly decide which modeling framework to go forward with<br>\n",
    "To keep this simple - We use AUC and will choose the model that gives us the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d138a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqSklEQVR4nO3dfbxWc77/8ddbZWqShDonJSVlTnSD7SaKimPKzdAwwmDGYegMw/BjNGeMu7kzZ5yZxrhpSAeDcIaIMXE4kRmh0paKTEOIKCElYfP5/bHW3nPt22vt2te12/t6Px+P67GvtdZ3rfVZ11XXd31v1veriMDMzErXFs0dgJmZNS9nBGZmJc4ZgZlZiXNGYGZW4pwRmJmVuLbNHUBjbb/99tG7d+/mDsPMrEWZN2/euxHRta5tLS4j6N27N3Pnzm3uMMzMWhRJr9W3zVVDZmYlzhmBmVmJc0ZgZlbinBGYmZU4ZwRmZiWuYBmBpCmSVkpaWM92Sbpa0lJJCyTtWahYzMysfoUsEdwMjG5g+xigX/o6A7i+gLGYmVk9CvYcQUTMktS7gSRHAbdGMg7205K2kdQ9IlYUKiYza9gdz7zO/eVvNncYVo8BO2zNpUfu1uTHbc42gh7AGznLy9N1tUg6Q9JcSXNXrVpVlODMStH95W+yeMWHzR2GFVlzPlmsOtbVOUtORNwA3ABQVlbmmXTMmlBuKWDxig8Z0H1r7jpzaDNHZcXUnCWC5cCOOcs9gbeaKRazkpVbChjQfWuOGlJnwdxaseYsEUwHzpZ0J7AvsMbtA2bNw6WA0lawjEDSVGAEsL2k5cClQDuAiJgEPAQcBiwF1gOnFioWs0JpDY2rldVBVroK2WvohDzbAzirUOc3K4bKapWW/EPq6iBrccNQmzWFprqTd+OqtQYeYsJKUlN1k/TdtLUGLhG0Iq2hvrpYfCdv9g8uEbQifhgoO9/Jm/2DSwStjO9yzayxXCIwMytxmUoEkrYABgM7AB8DiyLinUIGZmZmxdFgRiCpL3ARcAjwN2AV0B7oL2k98Hvgloj4otCBmplZYeQrEfyUZJ6AM9MHwKpI6gacCJwM3FKY8MzMrNAazAgaejo4IlYCE5s6IDMzK66NbiyW9K9NGYiZmTWPTek1dFOTRWFmZs0mX2Px9Po2Ads1fThmZlZs+RqLhwMnAetqrBewT0EislqyDh3R0kfBNLPmkS8jeBpYHxFP1NwgaUlhQrKasg517GETzGxj5Os1NKaBbQc2fThW192/B0gzs0LyEBObmboGjvOdvpkVkged2wz57t/MisklAjOzEueMwMysxGXOCCRd1tCymZm1TI0pEczLs2xmZi1Q5owgIh5oaNnMzFqmfENM/A6I+rZHxDlNHpGZmRVVvu6jc4sShZmZNZt8TxZXm3BGUseI+KiwIZmZWTFlaiOQNFTSYuDFdHmwpOsKGpmZmRVF1sbiicBXgdUAEfE84LGGzMxagcb0GnqjxqrPmzgWMzNrBlnHGnpD0v5ASNoSOIe0msjMzFq2rCWC8cBZQA/gTWBIumxmZi1cpowgIt6NiG9GxD9FRNeIOCkiVufbT9JoSUskLZU0oY7tnSU9IOl5SYsknboxF2FmZhsva6+hndMf7FWSVkq6X9LOefZpA1wLjAEGACdIGlAj2VnA4ogYDIwA/iutejIzsyLJWjV0B3A30B3YAfgfYGqeffYBlkbEKxHxKXAncFSNNAF0kiRgK+A9oCJjTGZm1gSyZgSKiD9EREX6uo0Ghp5I9QByexotT9flugb4F+At4AXg3Ij4otbJpTMkzZU0d9WqVRlDNjOzLBrMCCRtK2lbYKakCZJ6S9pJ0g+AP+U5tupYVzPz+CpQTlLKGAJcI6nWDO0RcUNElEVEWdeuXfOc1szMGiNf99F5JD/elT/qZ+ZsC+AnDey7HNgxZ7knyZ1/rlOBKyMigKWSXgW+AjybJy4zM2si+cYa6rMJx54D9JPUh6TL6fHAiTXSvA4cDDwp6Z+AXYFXNuGcZmbWSJknr5e0O0nvn/aV6yLi1vrSR0SFpLOBh4E2wJSIWCRpfLp9EkmJ4mZJL5CUOi6KiHc36krMzGyjZMoIJF1K0r1zAPAQSZfQvwD1ZgQAEfFQmj533aSc928BhzYqYjMza1JZew0dS1KF83ZEnAoMBr5UsKjMzKxosmYEH6fdOivSXj0rgQYfKDMzs5YhaxvBXEnbADeS9CRah3v2bLI7nnmd+8vfrLZu8YoPGdC9Vg9aM7OCyZQRRMR307eTJM0Ato6IBYULqzTcX/5mrR/+Ad235qghNZ+7MzMrnHyT1+/Z0LaIeK7pQ2p96rrzh3/c/d915tBmiMrMLJGvRPBfDWwLYFQTxtJq1XXnD777N7PNQ74HykYWK5DWznf+Zra5yjxVpZmZtU7OCMzMSpwzAjOzEpd1hjJJOknSJelyL0n7FDY0MzMrhqwlguuAocAJ6fJakmkozcyshcv6ZPG+EbGnpPkAEfG+5xY2M2sdspYIPksnow8ASV2BWlNKmplZy5M1I7gamAZ0k/QzkiGof16wqMzMrGiyjjV0u6R5JENRCzg6Il4saGQtTH3DSIAHkjOzzVvWiWl+C9wVEW4grkd9w0iAh5Iws81b1sbi54CLJfUnqSK6KyLmFi6slsnDSJhZS5SpjSAibomIw4B9gJeBX0r6W0EjMzOzomjsk8W7AF8BegMvNXk0ZmZWdFmfLK4sAVwBLAL2iogjCxqZmZkVRdY2gleBoRHxbiGDMTOz4ss3Q9lXIuIlkvmJe0nqlbvdM5SZmbV8+UoE5wNnUPdMZZ6hzMysFcg3Q9kZ6dsxEbEhd5uk9gWLyszMiiZrr6GnMq4zM7MWJl8bwT8DPYAOkvYgGV4CYGvgywWOzczMiiBfG8FXgW8DPYFf56xfC/xHgWJqMXLHF/J4QmbWUuVrI7gFuEXSMRFxT5FiajFyxxfyeEJm1lLlqxo6KSJuA3pLOr/m9oj4dR27lRSPL2RmLV2+xuKO6d+tgE51vBokabSkJZKWSppQT5oRksolLZL0RCNiNzOzJpCvauj36d/LG3vgdEaza4F/BZYDcyRNj4jFOWm2IZkPeXREvC6pW2PPU2xuFzCz1ibrWEP/KWlrSe0kPSbpXUkn5dltH2BpRLwSEZ8CdwJH1UhzInBvRLwOEBErG3sBxVbZLgCeZ8DMWoesYw0dGhE/kDSW5O7+G8BM4LYG9ukBvJGzvBzYt0aa/kA7SY+TVDX9NiJurXkgSWeQPOFMr169am4uisqSQGUpwO0CZtZaZH2grF369zBgakS8l2Ef1bEuaiy3BfYCDifpqvrjdPKb6jtF3BARZRFR1rVr14whN63cTMClADNrTbKWCB6Q9BLwMfBdSV2BDXn2WQ7smLPcE3irjjTvRsRHwEeSZgGDSSa/aXZ1tQe4JGBmrU3WGcomAEOBsoj4DPiI2vX9Nc0B+knqI2lL4Hhgeo009wPDJbWV9GWSqqMXG3MBheT2ADMrBVknr28HnAwcKAngCWBSQ/tERIWks4GHgTbAlIhYJGl8un1SRLwoaQawAPgCmBwRCzf6agrApQAza+2yVg1dT9JOcF26fHK67vSGdoqIh4CHaqybVGP5V8CvMsZhZmZNLGtGsHdEDM5Z/j9JzxciIDMzK66svYY+l9S3ckHSzsDnhQmp+d3xzOuM+/3sqvYBM7PWLGuJ4EJgpqRXSLqF7gScWrCompm7ippZKcmbEaRdRdeQPCncjSQjeCkiPilwbEXlrqJmVqoarBqSdDqwCPgdUA70jojnW1smAO4qamalK1+J4PvAbhGxKm0XuJ3azwK0Gi4FmFkpytdY/GlErAKIiFeALxU+JDMzK6Z8JYKekq6ubzkizilMWGZmViz5MoILayzPK1QgZmbWPLLMWWxmZq1Yvl5DN0javZ5tHSX9m6RvFiY0MzMrhnxVQ9cBl0gaCCwEVgHtgX7A1sAUkp5EZmbWQuWrGioHjpO0FVAGdCeZk+DFiFhS+PDMzKzQMg0xERHrgMcLG4qZmTWHrGMNtVo15yI2Mys1WUcfbbU8wJyZlbpGlQgkdUznF25VPLSEmZWyTCUCSftLWkw6n7CkwZKuy7ObmZm1AFmrhn4DfBVYDRARzwMHFiooMzMrnsxtBBHxRo1VrXaGMjOzUpK1jeANSfsDIWlL4BzSaiIzM2vZspYIxgNnAT2A5cAQ4LsFisnMzIooa4lg14ioNqaQpAOAvzZ9SGZmVkxZSwS/y7jOzMxamAZLBJKGAvsDXSWdn7Npa6BNIQMzM7PiyFc1tCWwVZquU876D4FjCxWUmZkVT77RR58AnpB0c0S8VqSYzMysiLI2Fq+X9CtgN5L5CACIiFEFicrMzIoma2Px7cBLQB/gcmAZMKdAMZmZWRFlzQi2i4ibgM8i4omI+DdgvwLGZWZmRZK1auiz9O8KSYcDbwE9CxOSmZkVU9YSwU8ldQb+H3ABMBn4fr6dJI2WtETSUkkTGki3t6TPJbknkplZkWWdqvLB9O0aYCRUPVlcL0ltgGuBfyUZlmKOpOkRsbiOdL8EHm5c6GZm1hQaLBFIaiPpBEkXSNo9XXeEpKeAa/Icex9gaUS8EhGfAncCR9WR7nvAPcDKxodvZmabKl+J4CZgR+BZ4GpJrwFDgQkRcV+efXsAuUNXLwf2zU0gqQcwFhgF7F3fgSSdAZwB0KtXrzynNTOzxsiXEZQBgyLiC0ntgXeBXSLi7QzHVh3rosbyROCiiPhcqit5ulPEDcANAGVlZTWPYWZmmyBfRvBpRHwBEBEbJL2cMROApASwY85yT5LeRrnKgDvTTGB74DBJFRlKG2Zm1kTyZQRfkbQgfS+gb7osICJiUAP7zgH6SeoDvAkcD5yYmyAi+lS+l3Qz8KAzATOz4sqXEfzLxh44IioknU3SG6gNMCUiFkkan26ftLHHNjOzppNv0LlNGmguIh4CHqqxrs4MICK+vSnnMjOzjZN58nozM2udnBGYmZW4zBmBpA6Sdi1kMGZmVnyZMgJJRwLlwIx0eYik6QWMy8zMiiRrieAykiEjPgCIiHKgdyECMjOz4sqaEVRExJqCRmJmZs0i63wECyWdCLSR1A84B3iqcGGZmVmxZC0RfI9kvuJPgDtIhqP+foFiMjOzIspaItg1In4E/KiQwZiZWfFlLRH8WtJLkn4iabeCRmRmZkWVKSOIiJHACGAVcIOkFyRdXMjAzMysODI/UBYRb0fE1cB4kmcKLilUUGZmVjxZHyj7F0mXSVpIMkXlUyTzC5iZWQuXtbH4v4GpwKERUXNyGTMza8EyZQQRsV+hAzEzs+bRYEYg6e6IOE7SC1SfbzjLDGVmZtYC5CsRnJv+PaLQgZiZWfNosLE4Ilakb78bEa/lvoDvFj48MzMrtKzdR/+1jnVjmjIQMzNrHvnaCP6d5M5/Z0kLcjZ1Av5ayMDMzKw48rUR3AH8GfgFMCFn/dqIeK9gUZmZWdHkywgiIpZJOqvmBknbOjMwM2v5spQIjgDmkXQfVc62AHYuUFxmZlYkDWYEEXFE+rdPccIxM7NiyzrW0AGSOqbvT5L0a0m9ChuamZkVQ9buo9cD6yUNBn4AvAb8oWBRmZlZ0TRm8voAjgJ+GxG/JelCamZmLVzW0UfXSvohcDIwXFIboF3hwjIzs2LJWiIYRzJx/b9FxNtAD+BXBYvKzMyKJutUlW8DtwOdJR0BbIiIWwsamZmZFUXWXkPHAc8C3wCOA56RdGyG/UZLWiJpqaQJdWz/pqQF6euptDHazMyKKGsbwY+AvSNiJYCkrsCjwB/r2yFtR7iWZMC65cAcSdMjYnFOsleBgyLifUljgBuAfRt/GWZmtrGythFsUZkJpFZn2HcfYGlEvBIRnwJ3kvQ6qhIRT0XE++ni03geZDOzostaIpgh6WGSeYshaTx+KM8+PYA3cpaX0/Dd/mkkA9zVIukM4AyAXr38HJuZWVPKOmfxhZK+DgwjGW/ohoiYlmc31bEu6liHpJEkGcGwes5/A0m1EWVlZXUew8zMNk6++Qj6AVcBfYEXgAsi4s2Mx14O7Jiz3BN4q45zDAImA2MiYnXGY5uZWRPJVyKYAtwKzAKOBH4HfD3jsecA/ST1Ad4EjgdOzE2Qjld0L3ByRLzciLg3yR3PvM795Ul+tnjFhwzovnWxTm1mttnJlxF0iogb0/dLJD2X9cARUSHpbOBhoA0wJSIWSRqfbp8EXAJsB1wnCZKhLMoaexGNdX/5m1UZwIDuW3PUkB6FPqWZ2WYrX0bQXtIe/KO+v0PuckQ0mDFExEPUaFROM4DK96cDpzc26KYwoPvW3HXm0OY4tZnZZiVfRrAC+HXO8ts5ywGMKkRQZmZWPPkmphlZrEDMzKx5ZH2gzMzMWilnBGZmJc4ZgZlZics6+qjSuYovSZd7SdqnsKGZmVkxZC0RXAcMBU5Il9eSjCxqZmYtXNZB5/aNiD0lzQdIh43esoBxmZlZkWTNCD5L5xcIqJqP4IuCRVUAHlbCzKxuWauGrgamAd0k/Qz4C/DzgkVVAJXDSgAeVsLMLEfWYahvlzQPOJhkeImjI+LFgkZWAB5WwsystkwZQTpK6Hrggdx1EfF6oQIzM7PiyNpG8CeS9gEB7YE+wBJgtwLFZWZmRZK1amhg7rKkPYEzCxKRmZkV1UY9WZwOP713E8diZmbNIGsbwfk5i1sAewKrChKRmZkVVdY2gk457ytI2gzuafpwzMys2PJmBOmDZFtFxIVFiMfMzIqswTYCSW0j4nOSqiAzM2uF8pUIniXJBMolTQf+B/iocmNE3FvA2MzMrAiythFsC6wmmaO48nmCAJwRmJm1cPkygm5pj6GF/CMDqBQFi8oso88++4zly5ezYcOG5g7FbLPQvn17evbsSbt27TLvky8jaANsRfUMoJIzAmt2y5cvp1OnTvTu3Ruprn+mZqUjIli9ejXLly+nT58+mffLlxGsiIgrNi00s8LZsGGDMwGzlCS22247Vq1q3GNe+Z4s9v8u2+w5EzD7h435/5AvIzh440IxM7OWosGMICLeK1YgZi3VVltttcnHmDt3Luecc06925ctW8Ydd9yROT1A7969GThwIIMGDeKggw7itdde2+Q4m8qkSZO49dZbm+RYK1as4Igjjqi27txzz6VHjx588cU/JlK87LLLuOqqq6ql6927N++++y4Ab7/9Nscffzx9+/ZlwIABHHbYYbz88subFNsnn3zCuHHj2GWXXdh3331ZtmxZnenuuusuBg0axG677cYPfvCDqvW//vWvGTBgAIMGDeLggw+u+g5XrVrF6NGjNym2XBs16JyZNa2ysjKuvvrqerfXzAjypa80c+ZMFixYwIgRI/jpT3+6yXFGRLUf1401fvx4TjnllE0+DiQ/lt/5zneqlr/44gumTZvGjjvuyKxZszIdIyIYO3YsI0aM4O9//zuLFy/m5z//Oe+8884mxXbTTTfRpUsXli5dynnnncdFF11UK83q1au58MILeeyxx1i0aBHvvPMOjz32GAB77LEHc+fOZcGCBRx77LFVmUTXrl3p3r07f/3rXzcpvkpZnyMw2+xd/sAiFr/1YZMec8AOW3PpkY2fdqO8vJzx48ezfv16+vbty5QpU+jSpQtz5szhtNNOo2PHjgwbNow///nPLFy4kMcff5yrrrqKBx98kCeeeIJzzz0XSOp7Z82axYQJE3jxxRcZMmQI3/rWt9hjjz2q0q9bt47vfe97zJ07F0lceumlHHPMMdXiGTp0aFXGsWrVKsaPH8/rryfzSk2cOJEDDjiAVatWceKJJ7J69Wr23ntvZsyYwbx581i3bh1jxoxh5MiRzJ49m/vuu4+7776bu+++m08++YSxY8dy+eWX89FHH3HcccexfPlyPv/8c3784x8zbtw4JkyYwPTp02nbti2HHnooV111FZdddhlbbbUVF1xwQb2f1YgRI9h3332ZOXMmH3zwATfddBPDhw+v9Vnfc8891TK5mTNnsvvuuzNu3DimTp3KiBEj8n5fM2fOpF27dowfP75q3ZAhQxr7tddy//33c9lllwFw7LHHcvbZZxMR1erxX3nlFfr370/Xrl0BOOSQQ7jnnns4+OCDGTlyZFW6/fbbj9tuu61q+eijj+b222/ngAMO2OQ4XSIwK4BTTjmFX/7ylyxYsICBAwdy+eWXA3DqqacyadIkZs+eTZs2berc96qrruLaa6+lvLycJ598kg4dOnDllVcyfPhwysvLOe+886ql/8lPfkLnzp154YUXWLBgAaNGjap1zBkzZnD00UcDSbXJeeedx5w5c7jnnns4/fTTAbj88ssZNWoUzz33HGPHjq3KKACWLFnCKaecwvz581myZAl/+9vfePbZZykvL2fevHnMmjWLGTNmsMMOO/D888+zcOFCRo8ezXvvvce0adNYtGgRCxYs4OKLL878WQFUVFTw7LPPMnHixGrrK7366qt06dKFL33pS1Xrpk6dygknnMDYsWN58MEH+eyzz+r7mqosXLiQvfbaK286gOHDhzNkyJBar0cffbRW2jfffJMdd9wRgLZt29K5c2dWr15dLc0uu+zCSy+9xLJly6ioqOC+++7jjTfeqHWsm266iTFjxlQtl5WV8eSTT2aKOR+XCKzV2Jg790JYs2YNH3zwAQcddBAA3/rWt/jGN77BBx98wNq1a9l///0BOPHEE3nwwQdr7X/AAQdw/vnn881vfpOvf/3r9OzZs8HzPfroo9x5551Vy126dKl6P3LkSN555x26detWddf86KOPsnjx4qo0H374IWvXruUvf/kL06ZNA2D06NHVjrPTTjux3377AfDII4/wyCOPsMceewCwbt06/va3vzF8+HAuuOACLrroIo444giGDx9ORUUF7du35/TTT+fwww+vVZdf32dV6etf/zoAe+21V5316ytWrKi6kwb49NNPeeihh/jNb35Dp06d2HfffXnkkUc4/PDD6+1N09heNo358Y2o/bhVzfN16dKF66+/nnHjxrHFFluw//7788orr1RLc9tttzF37lyeeOKJqnXdunXjrbfealTs9SloiUDSaElLJC2VNKGO7ZJ0dbp9QTrzmVmrVNePQl0mTJjA5MmT+fjjj9lvv/146aWX8h63vh+zmTNn8tprr7HbbrtxySWXAEkd+uzZsykvL6e8vJw333yTTp06NRhfx44dq53vhz/8YdX+S5cu5bTTTqN///7MmzePgQMH8sMf/pArrriCtm3b8uyzz3LMMcdw3333NbqBs/JOv02bNlRUVNTa3qFDh2pPlc+YMYM1a9YwcOBAevfuzV/+8hemTp0KwHbbbcf7779fbf+1a9eyzTbbsNtuuzFv3rxMMTWmRNCzZ8+qu/uKigrWrFnDtttuWyvdkUceyTPPPMPs2bPZdddd6devX9W2Rx99lJ/97GdMnz69Wslnw4YNdOjQIVPM+RQsI0iHr74WGAMMAE6QNKBGsjFAv/R1BnB9oeIxK5bOnTvTpUuXqjvHP/zhDxx00EF06dKFTp068fTTTwNUu4vP9fe//52BAwdy0UUXUVZWxksvvUSnTp1Yu3ZtnekPPfRQrrnmmqrlmj92HTp0YOLEidx666289957tdKXl5cDMGzYMO6++24gueuveZxKX/3qV5kyZQrr1q0DkuqPlStX8tZbb/HlL3+Zk046iQsuuIDnnnuOdevWsWbNGg477DAmTpxYda58n1VW/fv3r1ZSmDp1KpMnT2bZsmUsW7aMV199lUceeYT169dz4IEHMn369KrP8d5772Xw4MG0adOGUaNG8cknn3DjjTdWHWvOnDnV7sArPfnkk1WZYO7rkEMOqZX2a1/7GrfccgsAf/zjHxk1alSdmfbKlSuB5Lu77rrrqqrr5s+fz5lnnsn06dPp1q1btX1efvlldt9998yfVUMKWTW0D7A0Il4BkHQncBSwOCfNUcCtkdyKPC1pG0ndI2JFAeMya1Lr16+vVn1z/vnnc8stt1Q1gO68887893//N5DU837nO9+hY8eOjBgxgs6dO9c63sSJE5k5cyZt2rRhwIABjBkzhi222IK2bdsyePBgvv3tb1dVywBcfPHFnHXWWey+++60adOGSy+9tKpKpVL37t054YQTuPbaa7n66qs566yzGDRoEBUVFRx44IFMmjSJSy+9lBNOOIG77rqLgw46iO7du9OpU6eqH/xKhx56KC+++CJDhw4Fku6zt912G0uXLuXCCy9kiy22oF27dlx//fWsXbuWo446ig0bNhAR/OY3v6l1vfV9Vll07NiRvn37snTpUnbYYQcefvhhfv/731fbPmzYMB544AHGjRvH2WefzbBhw5BEt27dmDx5MpBU10ybNo3vf//7XHnllbRv357evXszceLEzLHU5bTTTuPkk09ml112Ydttt62W+Q8ZMqQqYzz33HN5/vnnAbjkkkvo378/ABdeeCHr1q2rqi7r1asX06dPB5LS3uGHH75J8VWJiIK8gGOByTnLJwPX1EjzIDAsZ/kxoKyOY50BzAXm9urVKzbGZdMXxmXTF27Uvrb5Wrx4cXOH0Chr166tev+LX/wizjnnnGaMproNGzbEZ599FhERTz31VAwePLh5A8ro3nvvjR/96EfNHUbRDR8+PN577706t9X1/wKYG/X8XheyRJBloLpMg9lFxA3ADQBlZWUbNdjd5tKQaKXtT3/6E7/4xS+oqKhgp5124uabb27ukKq8/vrrHHfccXzxxRdsueWW1apJNmdjx46t1ROntVu1ahXnn39+tQb9TVHIjGA5sGPOck+gZhN3ljRmrca4ceMYN25cc4dRp379+jF//vzmDmOjVNapl4quXbtWdQduCoXsNTQH6Cepj6QtgeOB6TXSTAdOSXsP7QesCbcPWCNFxt44ZqVgY/4/FKxEEBEVks4GHiaZ12BKRCySND7dPgl4CDgMWAqsB04tVDzWOrVv357Vq1ez3XbbeRRSK3mRzkfQvn37Ru2nlnY3VVZWFnPnzm3uMGwz4RnKzKqrb4YySfMioqyuffxksbVo7dq1a9RMTGZWm8caMjMrcc4IzMxKnDMCM7MS1+IaiyWtAjZ2qqXtgXebMJyWwNdcGnzNpWFTrnmniOha14YWlxFsCklz62s1b618zaXB11waCnXNrhoyMytxzgjMzEpcqWUENzR3AM3A11wafM2loSDXXFJtBGZmVluplQjMzKwGZwRmZiWuVWYEkkZLWiJpqaQJdWyXpKvT7Qsk7dkccTalDNf8zfRaF0h6StLg5oizKeW75px0e0v6XNKxxYyvELJcs6QRksolLZJUe9LdFibDv+3Okh6Q9Hx6zS16FGNJUyStlLSwnu1N//tV39RlLfVFMuT134GdgS2B54EBNdIcBvyZZIa0/YBnmjvuIlzz/kCX9P2YUrjmnHT/RzLk+bHNHXcRvudtSOYF75Uud2vuuItwzf8B/DJ93xV4D9iyuWPfhGs+ENgTWFjP9ib//WqNJYJ9gKUR8UpEfArcCRxVI81RwK2ReBrYRlL3YgfahPJec0Q8FRHvp4tPk8wG15Jl+Z4BvgfcA6wsZnAFkuWaTwTujYjXASKipV93lmsOoJOSCSm2IskIKoobZtOJiFkk11CfJv/9ao0ZQQ/gjZzl5em6xqZpSRp7PaeR3FG0ZHmvWVIPYCwwqYhxFVKW77k/0EXS45LmSTqlaNEVRpZrvgb4F5Jpbl8Azo2IL4oTXrNo8t+v1jgfQV3TVNXsI5slTUuS+XokjSTJCIYVNKLCy3LNE4GLIuLzVjJ7WZZrbgvsBRwMdABmS3o6Il4udHAFkuWavwqUA6OAvsD/SnoyIj4scGzNpcl/v1pjRrAc2DFnuSfJnUJj07Qkma5H0iBgMjAmIlYXKbZCyXLNZcCdaSawPXCYpIqIuK8oETa9rP+2342Ij4CPJM0CBgMtNSPIcs2nAldGUoG+VNKrwFeAZ4sTYtE1+e9Xa6wamgP0k9RH0pbA8cD0GmmmA6ekre/7AWsiYkWxA21Cea9ZUi/gXuDkFnx3mCvvNUdEn4joHRG9gT8C323BmQBk+7d9PzBcUltJXwb2BV4scpxNKcs1v05SAkLSPwG7Aq8UNcriavLfr1ZXIoiICklnAw+T9DiYEhGLJI1Pt08i6UFyGLAUWE9yR9FiZbzmS4DtgOvSO+SKaMEjN2a85lYlyzVHxIuSZgALgC+AyRFRZzfEliDj9/wT4GZJL5BUm1wUES12eGpJU4ERwPaSlgOXAu2gcL9fHmLCzKzEtcaqITMzawRnBGZmJc4ZgZlZiXNGYGZW4pwRmJmVOGcEJSAdebM859W7gbTrmuB8N0t6NT3Xc5KGbsQxJksakL7/jxrbntrUGNPjVH4uC9PRK7fJk36IpMM24jzdJT2Yvh8haY2k+ZJelHTpRhzva5WjcEo6uvJzSpevkHRIY49ZxzluVp7RWtNhLDJ3QU6v/cEM6eocfVPSVZJGZT2fZeeMoDR8HBFDcl7LinDOCyNiCDAB+H1jd46I0yNicbr4HzW27b/p4QH/+Fx2Jxnk66w86YeQ9N9urPOBG3OWn4yIPUiefD5J0l6NOVhETI+IK9PFo4EBOdsuiYhHNyLGzcnNwOg61v+O5N+TNTFnBCVI0laSHkvv1l+QVGvUzvQudlbOHfPwdP2hkman+/6PpK3ynG4WsEu67/npsRZK+n66rqOkPykZS36hpHHp+scllUm6EuiQxnF7um1d+veu3Dv09C72GEltJP1K0hwl47WfmeFjmU06cJekfZTM2TA//btr+lTrFcC4NJZxaexT0vPMr+tzTB0DzKi5Mh0GYh7QNy1tPJ3GO01SlzSWcyQtTtffma77tqRrJO0PfA34VRpT38o7eUljJN2d89mMkPRA+r5R36GkS9JrXCjpBqnawE0npZ/RQkn7pOmzfi51qm/0zYh4DdhO0j835niWQbHG2Par+V7A5ySDcpUD00ieKN863bY9yROKlQ8Xrkv//j/gR+n7NkCnNO0soGO6/iLgkjrOdzPp2P/AN4BnSAZCewHoSDJU8CJgD5IfyRtz9u2c/n0cKMuNKSdNZYxjgVvS91uSjMjYATgDuDhd/yVgLtCnjjjX5Vzf/wCj0+Wtgbbp+0OAe9L33wauydn/58BJ6fttSMbz6VjjHH2AeTnLI4AH0/fbAcuA3UieBD4oXX8FMDF9/xbwpcpz1Iwj97POXU6/49dzvqvrgZM28jvcNmf9H4Ajc76jG9P3B5KOn1/f51Lj2stInnqu799sb+oYj5+kZHVMc/+fam2vVjfEhNXp40iqaQCQ1A74uaQDSYYh6AH8E/B2zj5zgClp2vsiolzSQSTVEH9Nbwq3JLmTrsuvJF0MrCIZ7fRgYFokd8FIuhcYTnKnfJWkX5L8SDzZiOv6M3C1pC+RVCXMioiPJR0KDMqp4+4M9ANerbF/B0nlJD8684D/zUl/i6R+JKM6tqvn/IcCX5N0QbrcHuhF9bF9uqefQa7hkuaTfPZXkgwitk1EVM4mdgtJxgRJBnG7pPuA++qJo5ZIhmaYARwp6Y/A4cAPgMZ8h5VGSvoB8GVgW5JM/IF029T0fLMkba2knaW+zyU3vrnA6VmvJ8dKYIeN2M8a4IygNH2TZCanvSLiM0nLSP6zVkn/Yx9I8gPyB0m/At4H/jciTshwjgsj4o+VC6qnATMiXk7ryA8DfiHpkYi4IstFRMQGSY+TDEM8jvRHiWS8me9FxMN5DvFxRAyR1Bl4kKSN4GqSsWtmRsRYJQ3rj9ezv0juTpc0dA5qfLYkbQRHVB0kOX99Die52/4a8GNJuzWQtqa7SK7pPWBORKxNq3WyfodIag9cR1I6e0PSZVS/nppj1AT1fC5KBoTbVO1JPlNrQm4jKE2dgZVpJjAS2KlmAkk7pWluBG4imTrvaeAASZV1/l+W1D/jOWcBR6f7dCSp1nlS0g7A+oi4DbgqPU9Nn6Ulk7rcSTLo1nCSgclI//575T6S+qfnrFNErAHOAS5I9+kMvJlu/nZO0rUkVWSVHga+V1lnLmmPOg7/MkmJo17p+d9X2g4DnAw8IWkLYMeImElyN78NSbVarpox5Xqc5PP8DkmmAI3/Dit/9N9N2xJq9iSqbNMZRjIK5hqyfS4bqz/QYgfR21w5IyhNtwNlkuaSlA5eqiPNCKA8rcI4BvhtRKwi+WGcKmkByY/KV7KcMCKeI6l3fpakzWByRMwHBgLPplU0PwJ+WsfuNwALlDYW1/AIyR3zo5FMZQjJnAuLgeeUdEH8PXlKv2ksz5MMc/yfJKWTv5K0H1SaCQyobCwmKTm0S2NbmC7XPO5HwN8rf3gb8C2S6rQFJL2TrkjPfZuSUTXnA7+JiA9q7HcncGHaKNu3xrk/JynpjEn/0tjvMD3fjSTtO/eRVBnmel9Jd95JJFWAkOFzUdIRYHJd51Qy+uZsYFdJyyWdlq5vR9LxYG598drG8eijZgUmaSxJNdzFzR1LS5Z+jntGxI+bO5bWxm0EZgUWEdMkbdfccbQCbYH/au4gWiOXCMzMSpzbCMzMSpwzAjOzEueMwMysxDkjMDMrcc4IzMxK3P8HUQT0epUe/VEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for kNN\n",
    "metrics.plot_roc_curve(knn,X_test,y_test)\n",
    "plt.show()\n",
    "\n",
    "# ROC curve for Logistic Model\n",
    "metrics.plot_roc_curve(lr_model,X_test,y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa344f",
   "metadata": {},
   "source": [
    ">**Decision Point:**<br>\n",
    "AUC is highest for our Logistic Model (0.92) vs. KNN (0.88) so I will use that model to further evaluate probability thresholds and corresponding performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad833dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>78</td>\n",
       "      <td>102</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>102</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.60</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.70</td>\n",
       "      <td>61</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>52</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.90</td>\n",
       "      <td>36</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  TP   TN   FP  FN  Precision  Recall   F1  Accuracy\n",
       "0        0.00  89    0  118   0       0.43    1.00 0.60      0.43\n",
       "1        0.10  85   72   46   4       0.65    0.95 0.77      0.76\n",
       "2        0.20  85   94   24   4       0.78    0.95 0.86      0.86\n",
       "3        0.30  80   97   21   9       0.79    0.90 0.84      0.86\n",
       "4        0.40  78  102   16  11       0.83    0.88 0.85      0.87\n",
       "5        0.50  75  102   16  14       0.82    0.84 0.83      0.86\n",
       "6        0.60  67  103   15  22       0.82    0.75 0.78      0.82\n",
       "7        0.70  61  108   10  28       0.86    0.69 0.76      0.82\n",
       "8        0.80  52  112    6  37       0.90    0.58 0.71      0.79\n",
       "9        0.90  36  116    2  53       0.95    0.40 0.57      0.73\n",
       "10       1.00   0  118    0  89       0.00    0.00 0.00      0.57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_perf_measures(lr_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c561ae",
   "metadata": {},
   "source": [
    "For this problem statement, **false positives** would be detrimental to the business. This is because, if we predict that an applicant should be **approved when they shouldn't be**, it is a major risk to the bank. However, if we predict that an applicant should **not be approved when they should be**, it does not pose any risk to the bank. Hence, we focus on **Precision**\n",
    "\n",
    "1. **Prob Threshold = 0.2**:\n",
    "    - False positives are relatively high (24), while we have 4 false negatives.\n",
    "    - Precision is 0.78. Recall is 0.95\n",
    "    - Accuracy is 86%, which is good.\n",
    "    - F1 score is 0.86\n",
    "    - Considering that false positives are worse for the business than false negatives (as explained above), we should check other probability thresholds to see if false positives can be minimized further (precision maximized)\n",
    "<br><br>\n",
    "2. **Prob Threshold = 0.6**:\n",
    "    - With this threshold, the false positives have now reduced to 15. False negatives have increased to 22\n",
    "    - The Precision has increased to 0.82. Recall has dropped to 0.75\n",
    "    - F1 score has dropped to 0.78\n",
    "    - Accuracy has dropped to 82%, which is still good.\n",
    "    - This is better than the threshold of 0.2, considering that the Precision has increased. This is better for the business\n",
    "    - We shall check one more probability threshold to confirm we can get a higher Precision (considering it is a bank dealing with large sums of money, I would say a Precision of at least 0.9 would bring the least risk to the bank)\n",
    "<br><br>\n",
    "3. **Prob Threshold = 0.8**:\n",
    "    - With this threshold, we observe that while the Precision has increased to 0.9 (which is good), the Recall has fallen to 0.58\n",
    "    - False negatives have increased to 37. False positives have reduced to 6\n",
    "    - Accuracy has dropped to 79%\n",
    "    - F1 score has dropped to 0.71\n",
    "    - While this is better than threshold 0.2 and 0.6 (keeping Precision in mind), I wonder if we may have some angry customers who are being denied loans for no fault of theirs... I would say a threshold in between 0.6 and 0.8 would be the best.\n",
    "<br><br>\n",
    "4. **Which threshold to choose?**\n",
    "    - We choose the threshold = 0.6, as this threshold displays the best performance measures:\n",
    "        - While Precision is at 0.82 (which is not the highest), this threshold does strike a good balance between all performance measures (while focusing on Precision). We also avoid angry customers (which is also a sort of risk to the bank, but not as much as approving a loan when it shouldn't be)\n",
    "        - Accuracy is good (82%)\n",
    "        - F1 score is not the highest, but is balanced (considering we want to maximize Precision) (0.78)\n",
    "        \n",
    "     - While we have focused on the business requirement and tried to maximize Precision (thereby lower false positives and the overall risk to the bank), we must also consider that we shouldn't have too many customers being denied loans when they should have been approved (another type of risk).\n",
    "         - Hence, at ths point I would probably interview the bank and understand where their focus lies. Depending on this I would revisit this probability threshold.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1249565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>72</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.60</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.70</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.90</td>\n",
       "      <td>43</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>43</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  TP   TN   FP  FN  Precision  Recall   F1  Accuracy\n",
       "0        0.00  89    0  118   0       0.43    1.00 0.60      0.43\n",
       "1        0.10  84   60   58   5       0.59    0.94 0.73      0.70\n",
       "2        0.20  84   60   58   5       0.59    0.94 0.73      0.70\n",
       "3        0.30  79   87   31  10       0.72    0.89 0.79      0.80\n",
       "4        0.40  79   87   31  10       0.72    0.89 0.79      0.80\n",
       "5        0.50  72   99   19  17       0.79    0.81 0.80      0.83\n",
       "6        0.60  56  108   10  33       0.85    0.63 0.72      0.79\n",
       "7        0.70  56  108   10  33       0.85    0.63 0.72      0.79\n",
       "8        0.80  56  108   10  33       0.85    0.63 0.72      0.79\n",
       "9        0.90  43  113    5  46       0.90    0.48 0.63      0.75\n",
       "10       1.00  43  113    5  46       0.90    0.48 0.63      0.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_perf_measures(knn,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4ebcf",
   "metadata": {},
   "source": [
    "Just for reference, I output the performance measures of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc48a9",
   "metadata": {},
   "source": [
    "# 5. Deployment of Model <a class=\"anchor\" id=\"model-deployment\"></a>\n",
    "\n",
    "We now deploy our model so that the business can interact with it and start to make decisions (or evaluate it).\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "- Pickle the model object so that it may be used by streamlit\n",
    "\n",
    "- Create a streamlit app that allows the user to input the values as required by the model. Note - to allow for a simpler user experience, we can attempt to create a GUI that takes categorical variables in their ORIGINAL form, rather than their dummy form. We can easily convert this original form to dummy form in our code.\n",
    "\n",
    "- **This has been completed for part 1 (system administrators)**\n",
    "\n",
    "\n",
    "* [Go to Top](#table-of-content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
